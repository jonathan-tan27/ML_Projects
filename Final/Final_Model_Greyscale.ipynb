{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grey-scale input model\n",
    "\n",
    "Cells below we're used for testing grey-scale input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zipfile\n",
    "\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "TRAIN_LABEL_FILE = 'Data/train_labels.csv'\n",
    "TRAIN_IMAGES_DIR = 'Data/train'\n",
    "CHECKPOINT_DIR = 'Checkpoint_V1'\n",
    "BLOB_ACCOUNT_NAME = 'jtmlblobdatasets'\n",
    "BLOB_ACCOUNT_KEY = '' # Removed for privacy\n",
    "BLOB_CONTAINER = 'histcancerdetectiondata'\n",
    "BLOB_NAME = 'train.zip'\n",
    "DATASET_ZIP = 'Data/data.zip'\n",
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped dataset from Azure Blob Storage\n",
    "if (not os.path.isfile(DATASET_ZIP)):\n",
    "    training_labels = pd.read_csv(TRAIN_LABEL_FILE)\n",
    "    blob_service = BlockBlobService(account_name = BLOB_ACCOUNT_NAME, account_key = BLOB_ACCOUNT_KEY)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob_service.get_blob_to_path(container_name = BLOB_CONTAINER, blob_name = BLOB_NAME, file_path = DATASET_ZIP)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print('Time to download: {} mins', round((end_time - start_time)/ 60., 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing access to zip file\n",
    "archive = zipfile.ZipFile(DATASET_ZIP, 'r')\n",
    "img = Image.open(archive.open('000aa5d8f68dc1f45ebba53b8f159aae80e06072.tif'))\n",
    "plt.imshow(img)\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCamDatasetFromZipfile Class\n",
    "class PCamDatasetFromZipfile2(Dataset):\n",
    "    \"\"\"  Histopathologic Cancer Detection Dataset from Zip File       \"\"\"\n",
    "    \"\"\"  Updated to apply different transforms to train/dev/test set  \"\"\"\n",
    "    def __init__(self, zip_file, csv_file, train_indices, train_transform, test_transform):\n",
    "        self.archive = zipfile.ZipFile(zip_file, 'r')\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.train_indices = train_indices\n",
    "        self.train_transform = train_transform\n",
    "        self.test_transform = test_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.labels.iloc[idx, 0] + '.tif'\n",
    "        image = Image.open(self.archive.open(file))\n",
    "        label = self.labels.iloc[idx, 1]\n",
    "        label = int(label.reshape((1)))\n",
    "        \n",
    "        if (idx in self.train_indices):\n",
    "            image = self.train_transform(image)\n",
    "        else:\n",
    "            image = self.test_transform(image)\n",
    "            \n",
    "        return file, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCamDatasetFromAnalysisData(Dataset):\n",
    "    \"\"\"Histopathologic Cancer Detection Dataset from Analysis Data\"\"\"\n",
    "    def __init__(self, analysis_data, transform):\n",
    "        self.data = analysis_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.data[idx]['file']\n",
    "        label = self.data[idx]['y_true']\n",
    "        image = self.data[idx]['image']\n",
    "        return file, self.transform(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 -- +1 Conv/FC & Dropout & for B/W Images\n",
    "class CNN_V2_BW(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network\"\"\"\n",
    "    def __init__(self, p = 0.5):\n",
    "        super(CNN_V2_BW, self).__init__()\n",
    "        # 1. Convolutional layers\n",
    "        self.conv1 = nn.Conv2d( in_channels = 1\n",
    "                               , out_channels = 16\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d( in_channels = 16\n",
    "                               , out_channels = 32\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d( in_channels = 32\n",
    "                               , out_channels = 64\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d( in_channels = 64\n",
    "                               , out_channels = 128\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d( kernel_size = 2\n",
    "                                 , stride = 2\n",
    "                                 , padding = 0 )\n",
    "        self.dropout = nn.Dropout(p = p)\n",
    "        \n",
    "        # 2. FC layers to final output\n",
    "        self.fc1 = nn.Linear(in_features = 128*6*6, out_features = 512)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(in_features = 256, out_features = 128)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(in_features = 128, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply 4x...\n",
    "        # Convolution Layers, followed by Batch Normalizations, Maxpool, and ReLU\n",
    "        x = self.bn1(self.conv1(x))                      # batch_size x 96 x 96 x 16\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 48 x 48 x 16\n",
    "        x = self.bn2(self.conv2(x))                      # batch_size x 48 x 48 x 32\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 24 x 24 x 32\n",
    "        x = self.bn3(self.conv3(x))                      # batch_size x 24 x 24 x 64\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 12 x 12 x 64\n",
    "        x = self.bn4(self.conv4(x))                      # batch_size x 12 x 12 x 128\n",
    "        x = self.pool(F.relu(x))                         # batch_size x  6 x  6 x 128\n",
    "        \n",
    "        # Flatten the output for each image\n",
    "        x = x.view(-1, self.num_flat_features(x))        # batch_size x 6*6*128\n",
    "        \n",
    "        # Apply 4 FC Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.fc_bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.fc_bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def show_image(image, label):\n",
    "    \"\"\"Show image with label\"\"\"\n",
    "    print('Label: ' + str(label[0]))\n",
    "    plt.show(image)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def training_accuracy(predicted, true, i, acc, tpr, tnr):\n",
    "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
    "    predicted = predicted.cpu()\n",
    "    true = true.cpu()\n",
    "    \n",
    "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
    "    true = true.data.numpy()\n",
    "    \n",
    "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
    "    #true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
    "    #true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
    "    acc = acc * (i) / (i + 1) + accuracy / (i + 1)\n",
    "    \n",
    "    tpr = 0.0\n",
    "    tnr = 0.0\n",
    "    #tpr = tpr * (i) / (i + 1) + true_positive_rate / (i + 1)\n",
    "    #tnr = tnr * (i) / (i + 1) + true_negative_rate / (i + 1)\n",
    "    return acc, tpr, tnr\n",
    "\n",
    "def dev_accuracy(predicted, target):\n",
    "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
    "    predicted = predicted.cpu()\n",
    "    target = target.cpu()\n",
    "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
    "    true = target.data.numpy()\n",
    "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
    "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
    "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
    "    return accuracy, true_positive_rate, true_negative_rate\n",
    "\n",
    "def train_dev_test_split_indices(dataset_size, train_split=0.8, dev_split=0.1, seed=30):\n",
    "    \"\"\"Given a dataset size, returns the train/dev/test split indices\"\"\"\n",
    "    indices = list(range(dataset_size))\n",
    "    train_split_end = int(np.floor(train_split * dataset_size))\n",
    "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_split_end]\n",
    "    dev_indices = indices[train_split_end:dev_split_end]\n",
    "    test_indices = indices[dev_split_end:]\n",
    "    return train_indices, dev_indices, test_indices\n",
    "\n",
    "def train_dev_test_split_indices_from_dataset(dataset, train_split=0.8, dev_split=0.1, seed=30):\n",
    "    \"\"\"Given a dataset, returns the train/dev/test split indices\"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_split_end = int(np.floor(train_split * dataset_size))\n",
    "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_split_end]\n",
    "    dev_indices = indices[train_split_end:dev_split_end]\n",
    "    test_indices = indices[dev_split_end:]\n",
    "    return train_indices, dev_indices, test_indices\n",
    "\n",
    "def fetch_state(epoch, model, optimizer, dev_loss_min, dev_acc_max):\n",
    "    \"\"\"Returns the state dictionary for a model and optimizer\"\"\"\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'dev_loss_min': dev_loss_min,\n",
    "        'dev_acc_max': dev_acc_max,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optim_dict': optimizer.state_dict()\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def save_checkpoint(state, is_best = False, checkpoint = CHECKPOINT_DIR):\n",
    "    \"\"\"Taken from CS230 PyTorch Code Examples\"\"\"\n",
    "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
    "    checkpoint + 'best.pth.tar'\n",
    "\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, 'last_v2_hybrid.pth.tar')\n",
    "    if (not os.path.exists(checkpoint)):\n",
    "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
    "        os.mkdir(checkpoint)\n",
    "    else:\n",
    "        print(\"Checkpoint Directory exists! \")\n",
    "    torch.save(state, filepath)\n",
    "    if (is_best):\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best_v2_hybrid.pth.tar'))\n",
    "        \n",
    "def load_checkpoint(model, optimizer = None, checkpoint = CHECKPOINT_DIR):\n",
    "    \"\"\"Taken from CS230 PyTorch Code Examples\"\"\"\n",
    "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
    "    optimizer assuming it is present in checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint: (string) filename which needs to be loaded\n",
    "        model: (torch.nn.Module) model for which the parameters are loaded\n",
    "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint):\n",
    "        raise(\"File doesn't exist {}\".format(checkpoint))\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN_V2_BW())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 1),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "num_epochs = 100\n",
    "total_epochs = 0\n",
    "early_stop_limit = 10\n",
    "bad_epoch_count = 0\n",
    "stop = False\n",
    "train_loss_min = np.Inf\n",
    "dev_loss_min = np.Inf\n",
    "dev_acc_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset size to get train/dev/test indices\n",
    "dataset_size = len(pd.read_csv(TRAIN_LABEL_FILE))\n",
    "print(dataset_size)\n",
    "\n",
    "# Create data indices for train/dev set split\n",
    "train_indices, dev_indices, test_indices = train_dev_test_split_indices(dataset_size)\n",
    "\n",
    "# Create DataSet\n",
    "dataset = PCamDatasetFromZipfile2( zip_file = DATASET_ZIP\n",
    "                             , csv_file = TRAIN_LABEL_FILE\n",
    "                             , train_indices = train_indices\n",
    "                             , train_transform = train_transforms\n",
    "                             , test_transform = test_transforms )\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)   # 176,020 Images (Full) / [train_subset_size] Images (Subset)\n",
    "dev_sampler   = SubsetRandomSampler(dev_indices)     # 22,002 Images (Full) / [dev_subset_size] Images (Subset)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)    # 22,003 Images (Full)\n",
    "\n",
    "train_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = train_sampler )\n",
    "dev_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = dev_sampler )\n",
    "test_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = test_sampler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file, image, label = dataset[397]\n",
    "toPILImageTransform = transforms.ToPILImage()\n",
    "image = toPILImageTransform(image)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file, image, label = dataset[397]\n",
    "toPILImageTransform = transforms.ToPILImage()\n",
    "image = toPILImageTransform(image)\n",
    "plt.imshow(image)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = CNN_V2_BW()\n",
    "if (USE_GPU):\n",
    "    model.cuda()\n",
    "    \n",
    "lr = 5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = []\n",
    "train_acc_arr = []\n",
    "train_tpr_arr = []\n",
    "train_tnr_arr = []\n",
    "\n",
    "dev_loss_arr = []\n",
    "dev_acc_arr = []\n",
    "dev_tpr_arr = []\n",
    "dev_tnr_arr = []\n",
    "\n",
    "# Loop over the dataset multiple times\n",
    "total_num_epochs = total_epochs + num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    curr_epoch = total_epochs + epoch + 1\n",
    "    # Keep track of training loss\n",
    "    train_loss = []\n",
    "    # Keep track of dev loss\n",
    "    dev_loss = []\n",
    "    # Keep track of accuracy measurements\n",
    "    acc, tpr, tnr = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, (file, image, label) in enumerate(train_loader):\n",
    "        if USE_GPU:\n",
    "            data, target = image.cuda(), label.cuda()\n",
    "        else:\n",
    "            data, target = image, label\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Update target to be the same dimensions as output\n",
    "        target = target.view(output.shape[0], 1).float()\n",
    "        # Get accuracy measurements\n",
    "        acc, tpr, tnr = training_accuracy(output, target, batch_idx, acc, tpr, tnr)\n",
    "        # Calculate the batch's loss\n",
    "        curr_train_loss = criterion(output, target)\n",
    "        # Update the training loss\n",
    "        train_loss.append(curr_train_loss.item())\n",
    "        # Backward pass\n",
    "        curr_train_loss.backward()\n",
    "        # Perform a single optimization step to update parameters\n",
    "        optimizer.step()\n",
    "        # Print debug info every 32 batches\n",
    "        if (batch_idx) % 32 == 0:\n",
    "            print('Epoch {}/{}; Iter {}/{}; Loss: {:.4f}; Acc: {:.3f}; True Pos: {:.3f}; True Neg: {:.3f}'\n",
    "                   .format(curr_epoch, total_num_epochs, batch_idx + 1, len(train_loader), curr_train_loss.item(), acc, tpr, tnr))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (file, image, label) in enumerate(dev_loader):\n",
    "            if USE_GPU:\n",
    "                data, target = image.cuda(), label.cuda()\n",
    "            else:\n",
    "                data, target = image, label\n",
    "            # Get predicted output\n",
    "            output = model(data)\n",
    "            # Update target to be the same dimensions as output\n",
    "            target = target.view(output.shape[0], 1).float()\n",
    "            # Get accuracy measurements\n",
    "            dev_acc, dev_tpr, dev_tnr = dev_accuracy(output, target)\n",
    "            # Calculate the batch's loss\n",
    "            curr_dev_loss = criterion(output, target)\n",
    "            # Update the dev loss\n",
    "            dev_loss.append(curr_dev_loss.item())\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_train_loss = np.mean(np.array(train_loss))\n",
    "    avg_dev_loss = np.mean(np.array(dev_loss))\n",
    "    \n",
    "    # Update dev loss arrays\n",
    "    dev_loss_arr.append(avg_dev_loss)\n",
    "    dev_acc_arr.append(dev_acc)\n",
    "    dev_tpr_arr.append(dev_tpr)\n",
    "    dev_tnr_arr.append(dev_tnr)\n",
    "\n",
    "    # Update training loss arrays\n",
    "    train_loss_arr.append(avg_train_loss)\n",
    "    train_acc_arr.append(acc)\n",
    "    train_tpr_arr.append(tpr)\n",
    "    train_tnr_arr.append(tnr)\n",
    "\n",
    "    print('Epoch {}/{}; Avg. Train Loss: {:.4f}; Train Acc: {:.3f}; Train TPR: {:.3f}; Train TNR: {:.3f}; Epoch Time: {} mins; \\nAvg. Dev Loss: {:.4f}; Dev Acc: {:.3f}; Dev TPR: {:.3f}; Dev TNR: {:.3f}\\n'\n",
    "        .format(curr_epoch, total_num_epochs, avg_train_loss, acc, tpr, tnr, round((end_time - start_time)/ 60., 2), avg_dev_loss, dev_acc, dev_tpr, dev_tnr))\n",
    "    \n",
    "    if avg_dev_loss < dev_loss_min:\n",
    "        print('Dev loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
    "              .format(dev_loss_min, avg_dev_loss))\n",
    "        dev_loss_min = avg_dev_loss\n",
    "        is_best = False\n",
    "        if (dev_acc >= dev_acc_max):\n",
    "            is_best = True\n",
    "            dev_acc_max = dev_acc\n",
    "        state = fetch_state( epoch = curr_epoch\n",
    "                            , model = model\n",
    "                            , optimizer = optimizer\n",
    "                            , dev_loss_min = dev_loss_min\n",
    "                            , dev_acc_max = dev_acc_max )\n",
    "        save_checkpoint( state = state\n",
    "                        , is_best = is_best )\n",
    "        bad_epoch_count = 0\n",
    "    # If dev loss didn't improve, increase bad_epoch_count and stop if\n",
    "    # bad_epoch_count >= early_stop_limit\n",
    "    else:\n",
    "        bad_epoch_count += 1\n",
    "        print('{} epochs of increasing dev loss ({:.6f} --> {:.6f}).'\n",
    "              .format(bad_epoch_count, dev_loss_min, avg_dev_loss))\n",
    "        if (bad_epoch_count >= early_stop_limit):\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "\n",
    "    if (stop):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set plot\n",
    "plt.plot(train_loss_arr, color=\"red\")\n",
    "plt.plot(train_acc_arr, color=\"blue\")\n",
    "plt.plot(train_tpr_arr, color=\"green\")\n",
    "plt.plot(train_tnr_arr, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dev set plot\n",
    "plt.plot(dev_loss_arr, color=\"red\")\n",
    "plt.plot(dev_acc_arr, color=\"blue\")\n",
    "plt.plot(dev_tpr_arr, color=\"green\")\n",
    "plt.plot(dev_tnr_arr, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    acc, tpr, tnr = 0.0, 0.0, 0.0\n",
    "    y_true, y_hat = [], []\n",
    "    with torch.no_grad():\n",
    "        for file, image, label in dataloader:\n",
    "            if USE_GPU:\n",
    "                data, target = image.cuda(), label.cuda()\n",
    "            else:\n",
    "                data, target = image, label\n",
    "    \n",
    "            # Get predicted output\n",
    "            output = model(data)\n",
    "            #output = sigmoid(output.cpu()) >= 0.5\n",
    "            \n",
    "            # Update target to be the same dimensions as output\n",
    "            target = target.view(output.shape[0],1).float()\n",
    "            #target = target >= 0.5\n",
    "            \n",
    "            acc, tpr, tnr = training_accuracy(output, target, 1, acc, tpr, tnr)\n",
    "            #print('File: {}, Output: {}, Target: {}'.format(file, output, target))\n",
    "            \n",
    "            y_true.append(target >= 0.5)\n",
    "            y_hat.append(sigmoid(output.cpu()) >= 0.5)\n",
    "    return acc, tpr, tnr, y_true, y_hat\n",
    "\n",
    "def fetch_analysis_data(model, dataloader, totalToReturn):\n",
    "    model.eval()\n",
    "    truePositives = []\n",
    "    trueNegatives = []\n",
    "    falsePositives = []\n",
    "    falseNegatives = []\n",
    "    stopFetch = False\n",
    "    toPILImageTransform = transforms.ToPILImage()\n",
    "    with torch.no_grad():\n",
    "        for file, image, label in dataloader:\n",
    "            if USE_GPU:\n",
    "                data, target = image.cuda(), label.cuda()\n",
    "            else:\n",
    "                data, target = image, label\n",
    "            output = model(data)\n",
    "            output = sigmoid(output.cpu()) >= 0.5  \n",
    "            target = target.view(output.shape[0],1).float()\n",
    "            target = target.cpu() >= 0.5\n",
    "            for i in range(len(output)):\n",
    "                y_true = target[i]\n",
    "                y_hat = output[i]\n",
    "                sample = { \n",
    "                    'file' : file[i]\n",
    "                    , 'image' : toPILImageTransform(image[i])\n",
    "                    , 'y_true' : y_true.numpy()\n",
    "                    , 'y_hat' : y_hat.numpy()\n",
    "                }\n",
    "                if ( (len(truePositives) >= totalToReturn)\n",
    "                    and (len(falseNegatives) >= totalToReturn)\n",
    "                    and (len(trueNegatives) >= totalToReturn)\n",
    "                    and (len(falsePositives) >= totalToReturn) ):\n",
    "                    stopFetch = True\n",
    "                    break\n",
    "            \n",
    "                if (y_true == 1):\n",
    "                    if (y_hat == y_true):\n",
    "                        if (len(truePositives) >= totalToReturn):\n",
    "                            continue\n",
    "                        else:\n",
    "                            truePositives.append(sample)\n",
    "                    else:\n",
    "                        if (len(falseNegatives) >= totalToReturn):\n",
    "                            continue\n",
    "                        else:\n",
    "                            falseNegatives.append(sample)\n",
    "                else:\n",
    "                    if (y_hat == y_true):\n",
    "                        if (len(trueNegatives) >= totalToReturn):\n",
    "                            continue\n",
    "                        else:\n",
    "                            trueNegatives.append(sample)\n",
    "                    else:\n",
    "                        if (len(falsePositives) >= totalToReturn):\n",
    "                            continue\n",
    "                        else:\n",
    "                            falsePositives.append(sample)\n",
    "            if (stopFetch):\n",
    "                break\n",
    "    return truePositives, trueNegatives, falsePositives, falseNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    checkpoint = load_checkpoint(model = model, optimizer = None, checkpoint = best_checkpoint)\n",
    "\n",
    "    # Get accuracy\n",
    "    acc_t, tpr_t, tnr_t, y_true_t, y_hat_t = predict(test_model, test_loader)\n",
    "    print('Acc: {}, TPR: {}, TNR: {}'.format(acc_t, tpr_t, tnr_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    checkpoint = load_checkpoint(model = model, optimizer = None, checkpoint = best_checkpoint)\n",
    "\n",
    "    # Get accuracy\n",
    "    acc_t, tpr_t, tnr_t, y_true_t, y_hat_t = predict(test_model, dev_loader)\n",
    "    print('Acc: {}, TPR: {}, TNR: {}'.format(acc_t, tpr_t, tnr_t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
