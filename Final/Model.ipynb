{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Folder Structure:\n",
    "\n",
    "#### Root\n",
    "- Data/\n",
    "- - Test/                      # Contains evaluation images\n",
    "- - Train/                     # Contains training images\n",
    "- - sample_submission.csv      # Sample submission file for Kaggle competition\n",
    "- - train_labels.csv           # csv file containing training set labels in format (fileName, label)\n",
    "- Model.ipynb                  # Current file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "class PCamDataset(Dataset):\n",
    "    \"\"\"Histopathologic Cancer Detection Dataset\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with train labels.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.train_labels = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.train_labels.iloc[idx, 0])\n",
    "        img_name = img_name + '.tif'\n",
    "        image = Image.open(img_name)\n",
    "        label = self.train_labels.iloc[idx, 1:].values\n",
    "        return self.transform(image), int(label)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1. Convolutional layers\n",
    "        self.conv1 = nn.Conv2d( in_channels = 3\n",
    "                               , out_channels = 16\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d( in_channels = 16\n",
    "                               , out_channels = 32\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d( in_channels = 32\n",
    "                               , out_channels = 64\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d( kernel_size = 2\n",
    "                                 , stride = 2\n",
    "                                 , padding = 0 )\n",
    "\n",
    "        # 2. FC layers to final output\n",
    "        self.fc1 = nn.Linear(in_features = 64*12*12, out_features = 512)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(in_features = 256, out_features = 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply 3x...\n",
    "        # Convolution Layers, followed by Batch Normalizations, Maxpool, and ReLU\n",
    "        x = self.bn1(self.conv1(x))                      # batch_size x 96 x 96 x 16\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 48 x 48 x 16\n",
    "        x = self.bn2(self.conv2(x))                      # batch_size x 48 x 48 x 32\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 24 x 24 x 32\n",
    "        x = self.bn3(self.conv3(x))                      # batch_size x 24 x 24 x 64\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 12 x 12 x 64\n",
    "        \n",
    "        # Flatten the output for each image\n",
    "        x = x.view(-1, self.num_flat_features(x))        # batch_size x 12*12*64\n",
    "        \n",
    "        # Apply 3 FC Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_bn2(self.fc2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "def show_image(image, label):\n",
    "    \"\"\"Show image with label\"\"\"\n",
    "    print('Label: ' + str(label[0]))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
      "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc_bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Net())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev loss decreased (inf --> 0.000016).  Saving model ...\n",
      "Dev loss decreased (0.000016 --> 0.000015).  Saving model ...\n",
      "1 epochs of increasing dev loss\n",
      "Dev loss decreased (0.000015 --> 0.000014).  Saving model ...\n",
      "1 epochs of increasing dev loss\n",
      "2 epochs of increasing dev loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-d0636c75e8f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Perform a single optimization step to update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "train_label_file = 'Data\\\\train_labels.csv'\n",
    "train_set_dir = 'Data\\\\Train'\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "dev_split = 0.1                              # 90/10 Train/Dev split\n",
    "random_seed = 0                              # Set a random seed so the shuffle is predictable each run\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003, momentum = 0.9)\n",
    "train_on_gpu = False\n",
    "train_loss_min = np.Inf\n",
    "early_stop_limit = 20\n",
    "bad_epoch_count = 0\n",
    "num_epochs = 10\n",
    "stop = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create DataSet\n",
    "dataset = PCamDataset( csv_file = train_label_file\n",
    "                      , root_dir = train_set_dir\n",
    "                      , transform = transform )\n",
    "\n",
    "# Create data indices for train/dev set split\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(dev_split * dataset_size))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, dev_indices = indices[split:], indices[:split]\n",
    "\n",
    "######################################################\n",
    "### Starting with smaller train_sampler to ramp up ###\n",
    "######################################################\n",
    "temp_train_split = 10\n",
    "train_indices = indices[:temp_train_split]\n",
    "dev_indices = indices[temp_train_split:temp_train_split+10]\n",
    "######################################################\n",
    "\n",
    "# Create data samplers and loaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "dev_sampler = SubsetRandomSampler(dev_indices)\n",
    "\n",
    "train_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = train_sampler )\n",
    "dev_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = dev_sampler )\n",
    "\n",
    "# Train\n",
    "model = Net()\n",
    "if (train_on_gpu):\n",
    "    model.cuda()\n",
    "    \n",
    "# Loop over the dataset multiple times\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Keep track of training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), label.cuda()\n",
    "        else:\n",
    "            data, target = image, label\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the batch's loss\n",
    "        loss = criterion(output, target.float())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the training loss\n",
    "        train_loss += loss.item()\n",
    "                  \n",
    "    # Calculate average loss\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "                  \n",
    "    # Save model if train loss has decreased\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('Dev loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        train_loss_min,\n",
    "        train_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        train_loss_min = train_loss\n",
    "        bad_epoch_count = 0\n",
    "    # If train loss didn't improve, increase bad_epoch_count and stop if bad_epoch_count >= early_stop_limit (early stop)\n",
    "    else:\n",
    "        bad_epoch_count += 1\n",
    "        print('{} epochs of increasing dev loss'.format(bad_epoch_count))\n",
    "        if (bad_epoch_count >= early_stop_limit):\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "            break\n",
    "        \n",
    "    if (stop):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5152]])\n",
      "tensor([[0.]])\n",
      "tensor(0.7240)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "a = torch.empty(1, 1, dtype=torch.float)\n",
    "a.fill_(0.5152)\n",
    "print(a)\n",
    "\n",
    "t = torch.empty(1, 1, dtype=torch.float)\n",
    "t.fill_(0)\n",
    "print(t)\n",
    "print(nn.BCELoss()(a,t)) # Different numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
