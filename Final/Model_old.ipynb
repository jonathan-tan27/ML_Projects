{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Folder Structure:\n",
    "\n",
    "#### Root\n",
    "- Data/\n",
    "- - Test/                      # Contains evaluation images\n",
    "- - Train/                     # Contains training images\n",
    "- - sample_submission.csv      # Sample submission file for Kaggle competition\n",
    "- - train_labels.csv           # csv file containing training set labels in format (fileName, label)\n",
    "- Model.ipynb                  # Current file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "TRAIN_LABEL_FILE = 'Data\\\\train_labels.csv'\n",
    "TRAIN_IMAGES_DIR = 'Data\\\\Train'\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class PCamDataset(Dataset):\n",
    "    \"\"\"Histopathologic Cancer Detection Dataset\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with train labels.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.train_labels = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.train_labels.iloc[idx, 0])\n",
    "        img_name = img_name + '.tif'\n",
    "        image = Image.open(img_name)\n",
    "        label = self.train_labels.iloc[idx, 1:].values\n",
    "        return self.transform(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Class(es)\n",
    "class CNN_V1(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN_V1, self).__init__()\n",
    "        # 1. Convolutional layers\n",
    "        self.conv1 = nn.Conv2d( in_channels = 3\n",
    "                               , out_channels = 16\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d( in_channels = 16\n",
    "                               , out_channels = 32\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d( in_channels = 32\n",
    "                               , out_channels = 64\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d( kernel_size = 2\n",
    "                                 , stride = 2\n",
    "                                 , padding = 0 )\n",
    "\n",
    "        # 2. FC layers to final output\n",
    "        self.fc1 = nn.Linear(in_features = 64*12*12, out_features = 512)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(in_features = 256, out_features = 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply 3x...\n",
    "        # Convolution Layers, followed by Batch Normalizations, Maxpool, and ReLU\n",
    "        x = self.bn1(self.conv1(x))                      # batch_size x 96 x 96 x 16\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 48 x 48 x 16\n",
    "        x = self.bn2(self.conv2(x))                      # batch_size x 48 x 48 x 32\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 24 x 24 x 32\n",
    "        x = self.bn3(self.conv3(x))                      # batch_size x 24 x 24 x 64\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 12 x 12 x 64\n",
    "        \n",
    "        # Flatten the output for each image\n",
    "        x = x.view(-1, self.num_flat_features(x))        # batch_size x 12*12*64\n",
    "        \n",
    "        # Apply 3 FC Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_bn2(self.fc2(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def show_image(image, label):\n",
    "    \"\"\"Show image with label\"\"\"\n",
    "    print('Label: ' + str(label[0]))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "def test_accuracy(predicted, target):\n",
    "    \"\"\"Computes the accuracy\"\"\"\n",
    "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
    "    true = target.data.numpy()\n",
    "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
    "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
    "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
    "    return accuracy, true_positive_rate, true_negative_rate\n",
    "\n",
    "def batch_accuracy(output, target):\n",
    "    pred = torch.gt(output, 0.5)\n",
    "    truth = torch.gt(target, 0.5)\n",
    "    acc = pred.eq(truth).sum() / target.numel()\n",
    "    return acc\n",
    "\n",
    "def accuracy(data, target):\n",
    "    \"\"\"Computes the accuracy\"\"\"\n",
    "    num_tensors = len(data)\n",
    "    sum_acc = 0.0\n",
    "    for tensor_idx in range(num_tensors):\n",
    "        sum_acc += batch_accuracy(data[tensor_idx], target[tensor_idx])\n",
    "    return sum_acc / num_tensors * 100\n",
    "\n",
    "def train_dev_test_split_indices(dataset, train_split=0.8, dev_split=0.1, seed=30):\n",
    "    \"\"\"Given a dataset, returns the train/dev/test split indices\"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_split_end = int(np.floor(train_split * dataset_size))\n",
    "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_split_end]\n",
    "    dev_indices = indices[train_split_end:dev_split_end]\n",
    "    test_indices = indices[dev_split_end:]\n",
    "    return train_indices, dev_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_V1(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
      "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc_bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(CNN_V1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = CNN_V1()\n",
    "if (USE_GPU):\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss criterion\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "train_label_file = 'Data\\\\train_labels.csv'\n",
    "train_set_dir = 'Data\\\\Train'\n",
    "\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "num_epochs = 10\n",
    "early_stop_limit = 7\n",
    "bad_epoch_count = 0\n",
    "stop = False\n",
    "train_loss_min = np.Inf\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataSet\n",
    "dataset = PCamDataset( csv_file = TRAIN_LABEL_FILE\n",
    "                      , root_dir = TRAIN_IMAGES_DIR\n",
    "                      , transform = transform )\n",
    "\n",
    "# Create data indices for train/dev set split\n",
    "train_indices, dev_indices, test_indices = train_dev_test_split_indices(dataset)\n",
    "\n",
    "######################################################\n",
    "### Starting with smaller samplers to ramp up ###\n",
    "######################################################\n",
    "train_subset_size = 10\n",
    "dev_subset_size = 5\n",
    "train_indices = train_indices[:train_subset_size]\n",
    "dev_indices = dev_indices[:dev_subset_size]\n",
    "######################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices) # 176,020 Images (Full) / [train_subset_size] Images (Subset)\n",
    "dev_sampler   = SubsetRandomSampler(dev_indices)   # 22,002 Images (Full) / [dev_subset_size] Images (Subset)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)  # 22,003 Images\n",
    "\n",
    "train_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = train_sampler )\n",
    "dev_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = dev_sampler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy after 0 epochs: 0 %\n",
      "Dev accuracy after 0 epochs: 0 %\n",
      "Dev loss decreased (inf --> 0.000020).  Saving model ...\n",
      "Train accuracy after 1 epochs: 0 %\n",
      "Dev accuracy after 1 epochs: 0 %\n",
      "Dev loss decreased (0.000020 --> 0.000020).  Saving model ...\n",
      "Train accuracy after 2 epochs: 0 %\n",
      "Dev accuracy after 2 epochs: 0 %\n",
      "Dev loss decreased (0.000020 --> 0.000019).  Saving model ...\n",
      "Train accuracy after 3 epochs: 0 %\n",
      "Dev accuracy after 3 epochs: 0 %\n",
      "Dev loss decreased (0.000019 --> 0.000018).  Saving model ...\n",
      "Train accuracy after 4 epochs: 0 %\n",
      "Dev accuracy after 4 epochs: 0 %\n",
      "Dev loss decreased (0.000018 --> 0.000018).  Saving model ...\n",
      "Train accuracy after 5 epochs: 0 %\n",
      "Dev accuracy after 5 epochs: 0 %\n",
      "Dev loss decreased (0.000018 --> 0.000018).  Saving model ...\n",
      "Train accuracy after 6 epochs: 0 %\n",
      "Dev accuracy after 6 epochs: 0 %\n",
      "Dev loss decreased (0.000018 --> 0.000017).  Saving model ...\n",
      "Train accuracy after 7 epochs: 0 %\n",
      "Dev accuracy after 7 epochs: 0 %\n",
      "1 epochs of increasing dev loss\n",
      "Train accuracy after 8 epochs: 0 %\n",
      "Dev accuracy after 8 epochs: 0 %\n",
      "Dev loss decreased (0.000017 --> 0.000017).  Saving model ...\n",
      "Train accuracy after 9 epochs: 0 %\n",
      "Dev accuracy after 9 epochs: 0 %\n",
      "1 epochs of increasing dev loss\n"
     ]
    }
   ],
   "source": [
    "# Loop over the dataset multiple times\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Keep track of training loss\n",
    "    train_loss = 0.0\n",
    "    Y_prediction_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    # Keep track of dev loss\n",
    "    dev_loss = 0.0\n",
    "    Y_prediction_dev = []\n",
    "    Y_dev = []\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        if USE_GPU:\n",
    "            data, target = image.cuda(), label.cuda()\n",
    "        else:\n",
    "            data, target = image, label\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Update target to be the same dimensions as output\n",
    "        target = target.view(output.shape[0],1).float()\n",
    "        \n",
    "        # Store output and label to compute accuracy later\n",
    "        Y_prediction_train.append(output)\n",
    "        Y_train.append(target)\n",
    "\n",
    "        # Calculate the batch's loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the training loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(dev_loader):\n",
    "            if USE_GPU:\n",
    "                data, target = image.cuda(), label.cuda()\n",
    "            else:\n",
    "                data, target = image, label\n",
    "\n",
    "            # Get predicted output\n",
    "            output = model(data)\n",
    "\n",
    "            # Update target to be the same dimensions as output\n",
    "            target = target.view(output.shape[0],1).float()\n",
    "\n",
    "            # Store output and label to compute accuracy later\n",
    "            Y_prediction_dev.append(output)\n",
    "            Y_dev.append(target)\n",
    "\n",
    "            # Calculate the batch's loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Update the dev loss\n",
    "            dev_loss += loss.item()\n",
    "                  \n",
    "    # Calculate average loss\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    dev_loss = dev_loss/len(dev_loader.dataset)\n",
    "    \n",
    "    # Output accuracy for epoch\n",
    "    print('Train accuracy after {} epochs: {} %'\n",
    "          .format(epoch, accuracy(Y_prediction_train, Y_train)))\n",
    "    print('Dev accuracy after {} epochs: {} %'\n",
    "          .format(epoch, accuracy(Y_prediction_dev, Y_dev)))\n",
    "                  \n",
    "    # Save model if train loss has decreased\n",
    "    ### Focused on train loss at the moment because we want to overfit ###\n",
    "    ### the training data before worrying about our variance.          ###\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('Dev loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
    "              .format(train_loss_min, train_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        train_loss_min = train_loss\n",
    "        bad_epoch_count = 0\n",
    "    # If train loss didn't improve, increase bad_epoch_count and stop if\n",
    "    # bad_epoch_count >= early_stop_limit (early stop)\n",
    "    else:\n",
    "        bad_epoch_count += 1\n",
    "        print('{} epochs of increasing dev loss'.format(bad_epoch_count))\n",
    "        if (bad_epoch_count >= early_stop_limit):\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "        \n",
    "    if (stop):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "a = torch.empty(1, 1, dtype=torch.float)\n",
    "a.fill_(0.5152)\n",
    "print(a)\n",
    "\n",
    "t = torch.empty(1, 1, dtype=torch.float)\n",
    "t.fill_(0)\n",
    "print(t)\n",
    "print(nn.BCELoss()(a,t)) # Different numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
