{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Folder Structure:\n",
    "\n",
    "#### Root\n",
    "- Data/\n",
    "- - Test/                      # Contains evaluation images\n",
    "- - Train/                     # Contains training images\n",
    "- - sample_submission.csv      # Sample submission file for Kaggle competition\n",
    "- - train_labels.csv           # csv file containing training set labels in format (fileName, label)\n",
    "- Model.ipynb                  # Current file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "TRAIN_LABEL_FILE = 'Data\\\\train_labels.csv'\n",
    "TRAIN_IMAGES_DIR = 'Data\\\\Train'\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCamDataset(Dataset):\n",
    "    \"\"\"Histopathologic Cancer Detection Dataset\"\"\"\n",
    "    def __init__(self, csv_file, root_dir, transform):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with train labels.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.train_labels = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.train_labels.iloc[idx, 0])\n",
    "        img_name = img_name + '.tif'\n",
    "        image = Image.open(img_name)\n",
    "        label = self.train_labels.iloc[idx, 1:].values\n",
    "        return self.transform(image), int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Class(es)\n",
    "class CNN_V1(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN_V1, self).__init__()\n",
    "        # 1. Convolutional layers\n",
    "        self.conv1 = nn.Conv2d( in_channels = 3\n",
    "                               , out_channels = 16\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d( in_channels = 16\n",
    "                               , out_channels = 32\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d( in_channels = 32\n",
    "                               , out_channels = 64\n",
    "                               , kernel_size = 3\n",
    "                               , stride = 1\n",
    "                               , padding = 1 )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d( kernel_size = 2\n",
    "                                 , stride = 2\n",
    "                                 , padding = 0 )\n",
    "\n",
    "        # 2. FC layers to final output\n",
    "        self.fc1 = nn.Linear(in_features = 64*12*12, out_features = 512)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(in_features = 256, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply 3x...\n",
    "        # Convolution Layers, followed by Batch Normalizations, Maxpool, and ReLU\n",
    "        x = (self.conv1(x))                      # batch_size x 96 x 96 x 16\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 48 x 48 x 16\n",
    "        x = (self.conv2(x))                      # batch_size x 48 x 48 x 32\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 24 x 24 x 32\n",
    "        x = (self.conv3(x))                      # batch_size x 24 x 24 x 64\n",
    "        x = self.pool(F.relu(x))                         # batch_size x 12 x 12 x 64\n",
    "        \n",
    "        # Flatten the output for each image\n",
    "        x = x.view(-1, self.num_flat_features(x))        # batch_size x 12*12*64\n",
    "        \n",
    "        # Apply 3 FC Layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def show_image(image, label):\n",
    "    \"\"\"Show image with label\"\"\"\n",
    "    print('Label: ' + str(label[0]))\n",
    "    plt.imshow(image)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def training_accuracy(predicted, true, i, acc, tpr, tnr):\n",
    "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
    "    predicted = predicted.cpu()\n",
    "    true = true.cpu()\n",
    "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
    "    true = true.data.numpy()\n",
    "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
    "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
    "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
    "    acc = acc * (i) / (i + 1)  + accuracy / (i + 1)\n",
    "    tpr = tpr * (i) / (i + 1)  + true_positive_rate / (i + 1)\n",
    "    tnr = tnr * (i) / (i + 1) + true_negative_rate / (i + 1)\n",
    "    return acc, tpr, tnr\n",
    "\n",
    "def dev_accuracy(predicted, target):\n",
    "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
    "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
    "    true = target.data.numpy()\n",
    "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
    "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
    "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
    "    return accuracy, true_positive_rate, true_negative_rate\n",
    "\n",
    "#def batch_accuracy(output, target):\n",
    "#    pred = torch.gt(output, 0.5)\n",
    "#    truth = torch.gt(target, 0.5)\n",
    "#    acc = pred.eq(truth).sum() / target.numel()\n",
    "#    return acc\n",
    "#\n",
    "#def accuracy(data, target): ### Deprecated\n",
    "#    \"\"\"Computes the accuracy\"\"\"\n",
    "#    num_tensors = len(data)\n",
    "#    sum_acc = 0.0\n",
    "#    for tensor_idx in range(num_tensors):\n",
    "#        sum_acc += batch_accuracy(data[tensor_idx], target[tensor_idx])\n",
    "#    return sum_acc / num_tensors * 100\n",
    "\n",
    "def train_dev_test_split_indices(dataset, train_split=0.8, dev_split=0.1, seed=30):\n",
    "    \"\"\"Given a dataset, returns the train/dev/test split indices\"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    train_split_end = int(np.floor(train_split * dataset_size))\n",
    "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_split_end]\n",
    "    dev_indices = indices[train_split_end:dev_split_end]\n",
    "    test_indices = indices[dev_split_end:]\n",
    "    return train_indices, dev_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_V1(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
      "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc_bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(CNN_V1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "num_epochs = 10\n",
    "early_stop_limit = 3\n",
    "bad_epoch_count = 0\n",
    "stop = False\n",
    "train_loss_min = np.Inf\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataSet\n",
    "dataset = PCamDataset( csv_file = TRAIN_LABEL_FILE\n",
    "                      , root_dir = TRAIN_IMAGES_DIR\n",
    "                      , transform = transform )\n",
    "\n",
    "# Create data indices for train/dev set split\n",
    "train_indices, dev_indices, test_indices = train_dev_test_split_indices(dataset)\n",
    "\n",
    "######################################################\n",
    "### Starting with smaller samplers to ramp up ###\n",
    "######################################################\n",
    "train_subset_size = 10000\n",
    "dev_subset_size = 2500\n",
    "train_indices = train_indices[:train_subset_size]\n",
    "dev_indices = dev_indices[:dev_subset_size]\n",
    "######################################################\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)   # 176,020 Images (Full) / [train_subset_size] Images (Subset)\n",
    "dev_sampler   = SubsetRandomSampler(dev_indices)     # 22,002 Images (Full) / [dev_subset_size] Images (Subset)\n",
    "test_sampler  = SubsetRandomSampler(test_indices)    # 22,003 Images\n",
    "\n",
    "train_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = train_sampler )\n",
    "dev_loader = DataLoader( dataset = dataset\n",
    "                          , batch_size = batch_size\n",
    "                          , num_workers = num_workers\n",
    "                          , sampler = dev_sampler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = CNN_V1()\n",
    "if (USE_GPU):\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss criterion\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10; Iter 1/79; Loss: 0.6858; Acc: 0.648; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 5/79; Loss: 0.6616; Acc: 0.617; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 9/79; Loss: 0.6816; Acc: 0.598; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 13/79; Loss: 0.6554; Acc: 0.598; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 17/79; Loss: 0.6617; Acc: 0.593; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 21/79; Loss: 0.6428; Acc: 0.593; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 25/79; Loss: 0.6297; Acc: 0.590; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 29/79; Loss: 0.6143; Acc: 0.592; True Pos: 0.000; True Neg: 1.000\n",
      "Epoch 1/10; Iter 33/79; Loss: 0.5359; Acc: 0.605; True Pos: 0.031; True Neg: 0.997\n",
      "Epoch 1/10; Iter 37/79; Loss: 0.5849; Acc: 0.620; True Pos: 0.075; True Neg: 0.989\n",
      "Epoch 1/10; Iter 41/79; Loss: 0.6303; Acc: 0.628; True Pos: 0.126; True Neg: 0.968\n",
      "Epoch 1/10; Iter 45/79; Loss: 0.5584; Acc: 0.635; True Pos: 0.167; True Neg: 0.953\n",
      "Epoch 1/10; Iter 49/79; Loss: 0.5272; Acc: 0.649; True Pos: 0.208; True Neg: 0.948\n",
      "Epoch 1/10; Iter 53/79; Loss: 0.4395; Acc: 0.656; True Pos: 0.236; True Neg: 0.938\n",
      "Epoch 1/10; Iter 57/79; Loss: 0.4383; Acc: 0.663; True Pos: 0.271; True Neg: 0.927\n",
      "Epoch 1/10; Iter 61/79; Loss: 0.5069; Acc: 0.668; True Pos: 0.297; True Neg: 0.918\n",
      "Epoch 1/10; Iter 65/79; Loss: 0.4430; Acc: 0.675; True Pos: 0.314; True Neg: 0.919\n",
      "Epoch 1/10; Iter 69/79; Loss: 0.4366; Acc: 0.682; True Pos: 0.341; True Neg: 0.912\n",
      "Epoch 1/10; Iter 73/79; Loss: 0.5864; Acc: 0.685; True Pos: 0.361; True Neg: 0.904\n",
      "Epoch 1/10; Iter 77/79; Loss: 0.4964; Acc: 0.689; True Pos: 0.374; True Neg: 0.903\n",
      "Epoch 1/10; Loss: 0.5137; Train Acc: 0.691; Train TPR: 0.386; Train TNR: 0.898; Epoch Time: 5.76 mins; \n",
      "Dev Loss: 0.5479; Dev Acc: 0.735; Dev TPR: 0.778; Dev TNR: 0.707\n",
      "\n",
      "Train loss decreased (inf --> 0.000208).  Saving model ...\n",
      "Epoch 2/10; Iter 1/79; Loss: 0.4640; Acc: 0.797; True Pos: 0.797; True Neg: 0.797\n",
      "Epoch 2/10; Iter 5/79; Loss: 0.5633; Acc: 0.781; True Pos: 0.691; True Neg: 0.835\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-88e41798fd67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Save loss for loss plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_arr = []\n",
    "train_acc_arr = []\n",
    "train_tpr_arr = []\n",
    "train_tnr_arr = []\n",
    "\n",
    "dev_loss_arr = []\n",
    "dev_acc_arr = []\n",
    "dev_tpr_arr = []\n",
    "dev_tnr_arr = []\n",
    "\n",
    "# Loop over the dataset multiple times\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Keep track of training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Keep track of dev loss\n",
    "    dev_loss = 0.0\n",
    "    \n",
    "    # Test accuracy\n",
    "    loss_temp = []\n",
    "    acc, tpr, tnr = 0., 0., 0.\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        if USE_GPU:\n",
    "            data, target = image.cuda(), label.cuda()\n",
    "        else:\n",
    "            data, target = image, label\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Update target to be the same dimensions as output\n",
    "        target = target.view(output.shape[0],1).float()\n",
    "        \n",
    "        # Get accuracy measurements\n",
    "        acc, tpr, tnr = training_accuracy(output, target, batch_idx, acc, tpr, tnr)\n",
    "\n",
    "        # Calculate the batch's loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Save loss for loss plot\n",
    "        loss_temp.append(loss.item())\n",
    "        \n",
    "        # Perform a single optimization step to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the training loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Print debug info\n",
    "        if (batch_idx) % 4 == 0:\n",
    "            print('Epoch {}/{}; Iter {}/{}; Loss: {:.4f}; Acc: {:.3f}; True Pos: {:.3f}; True Neg: {:.3f}'\n",
    "                   .format(epoch+1, num_epochs, batch_idx + 1, len(train_loader), loss.item(), acc, tpr, tnr))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(dev_loader):\n",
    "            if USE_GPU:\n",
    "                data, target = image.cuda(), label.cuda()\n",
    "            else:\n",
    "                data, target = image, label\n",
    "\n",
    "            # Get predicted output\n",
    "            output = model(data)\n",
    "\n",
    "            # Update target to be the same dimensions as output\n",
    "            target = target.view(output.shape[0],1).float()\n",
    "\n",
    "            # Get accuracy measurements\n",
    "            dev_acc, dev_tpr, dev_tnr = dev_accuracy(output, target)\n",
    "            \n",
    "            # Calculate the batch's loss\n",
    "            curr_dev_loss = criterion(output, target)\n",
    "\n",
    "            # Update the dev loss\n",
    "            dev_loss += curr_dev_loss.item()\n",
    "            \n",
    "    # Update dev loss arrays\n",
    "    dev_loss_arr.append(curr_dev_loss)\n",
    "    dev_acc_arr.append(dev_acc)\n",
    "    dev_tpr_arr.append(dev_tpr)\n",
    "    dev_tnr_arr.append(dev_tnr)\n",
    "\n",
    "    print('Epoch {}/{}; Loss: {:.4f}; Train Acc: {:.3f}; Train TPR: {:.3f}; Train TNR: {:.3f}; Epoch Time: {} mins; \\nDev Loss: {:.4f}; Dev Acc: {:.3f}; Dev TPR: {:.3f}; Dev TNR: {:.3f}\\n'\n",
    "           .format(epoch+1, num_epochs, loss, acc, tpr, tnr, round((end_time - start_time)/ 60., 2), curr_dev_loss, dev_acc, dev_tpr, dev_tnr))\n",
    "    \n",
    "    # Training loss arrays\n",
    "    train_loss_arr.append(np.mean(np.array(loss_temp)))\n",
    "    train_acc_arr.append(acc)\n",
    "    train_tpr_arr.append(tpr)\n",
    "    train_tnr_arr.append(tnr)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    dev_loss = dev_loss/len(dev_loader.dataset)\n",
    "    \n",
    "    # Save model if train loss has decreased\n",
    "    ### Focused on train loss at the moment because we want to overfit ###\n",
    "    ### the training data before worrying about our variance.          ###\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('Train loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
    "              .format(train_loss_min, train_loss))\n",
    "        torch.save(model.state_dict(), 'model_v1.pt')\n",
    "        train_loss_min = train_loss\n",
    "        bad_epoch_count = 0\n",
    "    # If train loss didn't improve, increase bad_epoch_count and stop if\n",
    "    # bad_epoch_count >= early_stop_limit (early stop)\n",
    "    else:\n",
    "        bad_epoch_count += 1\n",
    "        print('{} epochs of increasing training loss'.format(bad_epoch_count))\n",
    "        if (bad_epoch_count >= early_stop_limit):\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "        \n",
    "    if (stop):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set plot\n",
    "plt.plot(train_loss_arr, color=\"red\")\n",
    "plt.plot(train_acc_arr, color=\"blue\")\n",
    "plt.plot(train_tpr_arr, color=\"green\")\n",
    "plt.plot(train_tnr_arr, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dev set plot\n",
    "plt.plot(dev_loss_arr, color=\"red\")\n",
    "plt.plot(dev_acc_arr, color=\"blue\")\n",
    "plt.plot(dev_tpr_arr, color=\"green\")\n",
    "plt.plot(dev_tnr_arr, color=\"orange\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
